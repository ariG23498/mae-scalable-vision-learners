{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mae-debug.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOsZtGU2Sn51U0KFQhOQAY7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R1xBElz3PDk"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUn7CggVEPer"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# setting seed\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rArMzRYX3REs"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmsKcx_JEkUt",
        "outputId": "50a0d97d-6935-4044-9495-63108c12c137"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
        "(x_train, y_train), (x_val, y_val) = (x_train[:40000], y_train[:40000]), (x_train[40000:], y_train[40000:])\n",
        "print(f\"Training samples: {len(x_train)}\")\n",
        "print(f\"Validation samples: {len(x_val)}\")\n",
        "print(f\"Testing samples: {len(x_test)}\")\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 15s 0us/step\n",
            "169017344/169001437 [==============================] - 15s 0us/step\n",
            "Training samples: 40000\n",
            "Validation samples: 10000\n",
            "Testing samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skJSCgbU3SOt"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM6sLLDAFJ4Y"
      },
      "source": [
        "INPUT_SHAPE = (32, 32, 3)\n",
        "NUM_CLASSES = 100\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "IMAGE_SIZE = 72  # We'll resize input images to this size\n",
        "PATCH_SIZE = 6  # Size of the patches to be extract from the input images\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "\n",
        "PROJECTION_DIM = 64\n",
        "NUM_HEADS = 4\n",
        "TRANSFORMER_UNITS = [\n",
        "    PROJECTION_DIM * 2,\n",
        "    PROJECTION_DIM,\n",
        "]  # Size of the transformer layers\n",
        "TRANSFORMER_LAYERS = 8\n",
        "MLP_HEAD_UNITS = [2048, 1024]  # Size of the dense layers of the final classifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI1OSyWMY9sU"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train))\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(1024)\n",
        "    .repeat()\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val))\n",
        "val_ds = (\n",
        "    val_ds\n",
        "    .shuffle(1024)\n",
        "    .repeat()\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test))\n",
        "test_ds = (\n",
        "    test_ds\n",
        "    .repeat()\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AYntKxt3WP5"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXDYQCvJF1C5"
      },
      "source": [
        "def get_augmentation_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.InputLayer(INPUT_SHAPE),\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        )],\n",
        "        name=\"data_augmentation\")\n",
        "\n",
        "    # Compute the mean and the variance of the training data for normalization.\n",
        "    model.layers[0].adapt(x_train)\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDj9obkbLQzj",
        "outputId": "d2a89ac4-522e-4bd2-9247-037de580cff5"
      },
      "source": [
        "images = tf.random.normal((2, 32, 32, 3))\n",
        "augmentation_model = get_augmentation_model()\n",
        "\n",
        "augmeneted_images = augmentation_model(images)\n",
        "augmeneted_images.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 72, 72, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx9cp2o53Z9w"
      },
      "source": [
        "# Create Patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okJv4FwlGOG3"
      },
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.patch_size = patch_size\n",
        "        # assuming the image has three channels each patch would be\n",
        "        # of size (patch_size, patch_size, 3)\n",
        "        self.resize = layers.Reshape((-1, patch_size*patch_size*3))\n",
        "\n",
        "    def call(self, images):\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patches = self.resize(patches)\n",
        "        return patches"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edMubiTsNo7c",
        "outputId": "0beaa25e-2133-4568-b30e-4a96e70db9ad"
      },
      "source": [
        "images = tf.random.normal((2, 32, 32, 3))\n",
        "augmentation_model = get_augmentation_model()\n",
        "augmeneted_images = augmentation_model(images)\n",
        "\n",
        "patches = Patches(patch_size=PATCH_SIZE)(augmeneted_images)\n",
        "patches.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 144, 108])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss7CMuiWGNmw"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC_K3lYKK15g"
      },
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, patch_size, projection_dim, batch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection_dim = projection_dim # 64\n",
        "        self.batch_size = batch_size\n",
        "        self.mask_token = tf.Variable(\n",
        "            tf.random.normal(\n",
        "                [1, patch_size*patch_size*3]\n",
        "            ))\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        (_, self.num_patches, self.patch_area) = input_shape\n",
        "\n",
        "        # create the projection layer\n",
        "        self.projection = layers.Dense(units=self.projection_dim)\n",
        "        \n",
        "        # create the positional embedding layer\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=self.num_patches, output_dim=self.projection_dim)\n",
        "        \n",
        "        # 75% of number of patches should be masked\n",
        "        self.num_mask = int(0.75 * self.num_patches)\n",
        "\n",
        "        # create random indices from a uniform distribution and then split\n",
        "        # it into mask and unmask indices\n",
        "        rand_indices = tf.argsort(\n",
        "            tf.random.uniform(shape=(self.batch_size, self.num_patches)),\n",
        "            axis=-1)\n",
        "        self.mask_indices = rand_indices[:, :self.num_mask]\n",
        "        self.unmask_indices = rand_indices[:, self.num_mask:]\n",
        "\n",
        "        # self.mask_token = tf.Variable(\n",
        "        #     initial_value=tf.random.normal([1, self.patch_area]),\n",
        "        #     trainable=True)\n",
        "        # self.mask_tokens = tf.repeat(self.mask_token, repeats=self.num_mask, axis=0)\n",
        "        # self.mask_tokens = tf.repeat(\n",
        "        #         self.mask_tokens[tf.newaxis, ...],\n",
        "        #         repeats=self.batch_size,\n",
        "        #         axis=0)\n",
        "\n",
        "    def call(self, patch):\n",
        "        # patch shape = (B, num_patches, p*p*3)\n",
        "        # get the positional embeddings\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        pos_embeddings = self.position_embedding(positions[tf.newaxis, ...])\n",
        "        pos_embeddings = tf.tile(pos_embeddings, [self.batch_size, 1, 1]) # (B, num_patches, projection_dim)\n",
        "\n",
        "        # embedd the patches\n",
        "        patch_embeddings = self.projection(patch) + pos_embeddings # (B, num_patches, projection_dim)\n",
        "\n",
        "        # the encoder input is the unmasked patch embeddings\n",
        "        unmasked_embeddings = tf.gather(\n",
        "            patch_embeddings,\n",
        "            self.unmask_indices,\n",
        "            axis=1,\n",
        "            batch_dims=1) # (B, unmask_numbers, projection_dim)\n",
        "\n",
        "        # get the unmasked and masked positions\n",
        "        unmasked_positions = tf.gather(\n",
        "            pos_embeddings,\n",
        "            self.unmask_indices,\n",
        "            axis=1,\n",
        "            batch_dims=1) # (B, unmask_numbers, projection_dim)\n",
        "        masked_positions = tf.gather(\n",
        "            pos_embeddings,\n",
        "            self.mask_indices,\n",
        "            axis=1,\n",
        "            batch_dims=1) # (B, mask_numbers, projection_dim)\n",
        "\n",
        "        mask_tokens = tf.repeat(self.mask_token, repeats=self.num_mask, axis=0)\n",
        "        mask_tokens = tf.repeat(\n",
        "                mask_tokens[tf.newaxis, ...],\n",
        "                repeats=self.batch_size,\n",
        "                axis=0)\n",
        "\n",
        "        # get the masked embeddings\n",
        "        masked_embeddings = self.projection(mask_tokens) + masked_positions\n",
        "\n",
        "        return unmasked_embeddings, masked_embeddings, unmasked_positions"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fGEGNLAMugh",
        "outputId": "1e3e2752-a77a-4dd4-d1a5-c8bf3647277e"
      },
      "source": [
        "images = tf.random.normal((2, 32, 32, 3))\n",
        "augmentation_model = get_augmentation_model()\n",
        "augmeneted_images = augmentation_model(images)\n",
        "\n",
        "patches = Patches(patch_size=PATCH_SIZE)(augmeneted_images)\n",
        "patch_encoder = PatchEncoder(patch_size=PATCH_SIZE, projection_dim=PROJECTION_DIM, batch_size=2)\n",
        "unmasked_embeddings, masked_embeddings, unmasked_positions = patch_encoder(patches)\n",
        "\n",
        "unmasked_embeddings.shape, masked_embeddings.shape, unmasked_positions.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([2, 36, 64]), TensorShape([2, 108, 64]), TensorShape([2, 36, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrqZHsrDfnDk"
      },
      "source": [
        "def get_mlp(hidden_units, dropout_rate):\n",
        "    layers_list = []\n",
        "    for units in hidden_units:\n",
        "        layers_list.append(layers.Dense(units, activation=tf.nn.gelu))\n",
        "        layers_list.append(layers.Dropout(dropout_rate))\n",
        "    \n",
        "    model = keras.Sequential(layers_list)\n",
        "    return model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5BRsEC2QaOp"
      },
      "source": [
        "class Encoder(layers.Layer):\n",
        "    def __init__(self, num_layers, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layer_norm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        self.add1 = layers.Add()\n",
        "        self.add2 = layers.Add()\n",
        "\n",
        "        self.mlp = get_mlp(hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        (_, self.num_unmask, self.projection_dim) = input_shape\n",
        "        self.mha1 = layers.MultiHeadAttention(\n",
        "            num_heads=self.num_heads,\n",
        "            key_dim=self.projection_dim//self.num_heads,\n",
        "            dropout=0.1\n",
        "        )\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        for _ in range(self.num_layers):\n",
        "            # Layer normalization 1.\n",
        "            x1 = self.layer_norm1(inputs)\n",
        "            # Create a multi-head attention layer.\n",
        "            attention_output = self.mha1(query=x1, value=x1)\n",
        "            # Skip connection 1.\n",
        "            x2 = self.add1([attention_output, inputs])\n",
        "            # Layer normalization 2.\n",
        "            x3 = self.layer_norm2(x2)\n",
        "            # MLP.\n",
        "            x3 = self.mlp(x3)\n",
        "            # Skip connection 2.\n",
        "            inputs = self.add2([x3, x2])\n",
        "\n",
        "        # Create the encoder ouputs\n",
        "        encoder_outputs = self.layer_norm3(inputs)\n",
        "        \n",
        "        return encoder_outputs"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce1QpJonS66D",
        "outputId": "3ea23f29-ba99-4807-bef8-8b9d36f8526a"
      },
      "source": [
        "images = tf.random.normal((2, 32, 32, 3))\n",
        "augmentation_model = get_augmentation_model()\n",
        "augmeneted_images = augmentation_model(images)\n",
        "\n",
        "patches = Patches(patch_size=PATCH_SIZE)(augmeneted_images)\n",
        "patch_encoder = PatchEncoder(patch_size=PATCH_SIZE, projection_dim=PROJECTION_DIM, batch_size=2)\n",
        "unmasked_embeddings, masked_embeddings, unmasked_positions = patch_encoder(patches)\n",
        "\n",
        "encoder = Encoder(num_layers=2, num_heads=2)\n",
        "encoder_outputs = encoder(unmasked_embeddings)\n",
        "encoder_outputs.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 36, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b0pdemuTn4K"
      },
      "source": [
        "class Decoder(layers.Layer):\n",
        "    def __init__(self, num_layers, num_heads, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_layers = num_layers\n",
        "        self.num_heads = num_heads\n",
        "        self.patch_size = patch_size\n",
        "        self.layer_norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layer_norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layer_norm3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.add1 = layers.Add()\n",
        "        self.add2 = layers.Add()\n",
        "        self.mlp = get_mlp(hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        (_, self.num_patches, self.projection_dim) = input_shape\n",
        "        self.mha1 = layers.MultiHeadAttention(\n",
        "            num_heads=self.num_heads,\n",
        "            key_dim=self.projection_dim//self.num_heads,\n",
        "            dropout=0.1)\n",
        "        self.dense = layers.Dense(\n",
        "            units=self.patch_size*self.patch_size*3,\n",
        "            activation=\"sigmoid\")\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        for _ in range(self.num_layers):\n",
        "            # Layer normalization 1.\n",
        "            x1 = self.layer_norm1(inputs)\n",
        "            # Create a multi-head attention layer.\n",
        "            attention_output = self.mha1(query=x1, value=x1)\n",
        "            # Skip connection 1.\n",
        "            x2 = self.add1([attention_output, inputs])\n",
        "            # Layer normalization 2.\n",
        "            x3 = self.layer_norm2(x2)\n",
        "            # MLP.\n",
        "            x3 = self.mlp(x3)\n",
        "            # Skip connection 2.\n",
        "            inputs = self.add1([x3, x2])\n",
        "\n",
        "        # Create the encoder ouputs\n",
        "        decoder_outputs = self.layer_norm3(inputs)\n",
        "        decoder_outputs = self.dense(decoder_outputs)\n",
        "        return decoder_outputs"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1bdj5yRU2vm",
        "outputId": "df983549-d4b9-40a7-cb12-493963e9f966"
      },
      "source": [
        "images = tf.random.normal((2, 32, 32, 3))\n",
        "augmentation_model = get_augmentation_model()\n",
        "augmeneted_images = augmentation_model(images)\n",
        "\n",
        "patches = Patches(patch_size=PATCH_SIZE)(augmeneted_images)\n",
        "print(patches.shape)\n",
        "patch_encoder = PatchEncoder(patch_size=PATCH_SIZE, projection_dim=PROJECTION_DIM, batch_size=2)\n",
        "unmasked_embeddings, masked_embeddings, unmasked_positions = patch_encoder(patches)\n",
        "\n",
        "encoder = Encoder(num_layers=2, num_heads=2)\n",
        "encoder_outputs = encoder(unmasked_embeddings)\n",
        "encoder_outputs = encoder_outputs + unmasked_positions\n",
        "decoder_inputs = tf.concat([encoder_outputs, masked_embeddings], axis=1)\n",
        "\n",
        "decoder = Decoder(num_layers=2, num_heads=2, patch_size=PATCH_SIZE)\n",
        "decoder_outputs = decoder(decoder_inputs)\n",
        "\n",
        "print(decoder_outputs.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 144, 108)\n",
            "(2, 144, 108)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2mm37Ew-S9X"
      },
      "source": [
        "class MaskedAutoencoder(keras.Model):\n",
        "    def __init__(self, augmentation_model, patch_layer, patch_encoder, encoder, decoder, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.augmentation_model = augmentation_model\n",
        "        self.patch_layer = patch_layer\n",
        "        self.patch_encoder = patch_encoder\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def compile(self, optimizer, loss, run_eagerly=False):\n",
        "        super().compile(run_eagerly=run_eagerly)\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "    \n",
        "    def train_step(self, images):\n",
        "        with tf.GradientTape() as tape:\n",
        "            augmeneted_images = self.augmentation_model(images)\n",
        "            patches = self.patch_layer(augmeneted_images)\n",
        "            (unmasked_embeddings, masked_embeddings, unmasked_positions) = self.patch_encoder(patches)\n",
        "            encoder_outputs = self.encoder(unmasked_embeddings)\n",
        "            encoder_outputs = encoder_outputs + unmasked_positions\n",
        "            decoder_inputs = tf.concat([encoder_outputs, masked_embeddings], axis=1)\n",
        "            decoder_outputs = self.decoder(decoder_inputs)\n",
        "            total_loss = self.loss(patches, decoder_outputs)\n",
        "        train_vars = [\n",
        "            self.augmentation_model.trainable_variables,\n",
        "            self.patch_layer.trainable_variables,\n",
        "            self.patch_encoder.trainable_variables,\n",
        "            self.encoder.trainable_variables,\n",
        "            self.decoder.trainable_variables,\n",
        "        ]\n",
        "        grads = tape.gradient(total_loss, train_vars)\n",
        "        tv_list = []\n",
        "        for (grad, var) in zip(grads, train_vars):\n",
        "            for g, v in zip(grad, var):\n",
        "                tv_list.append((g,v))\n",
        "        self.optimizer.apply_gradients(tv_list)\n",
        "    \n",
        "        return {\"loss\": total_loss}\n",
        "    \n",
        "    def test_step(self, images):\n",
        "        augmeneted_images = self.augmentation_model(images)\n",
        "        patches = self.patch_layer(augmeneted_images)\n",
        "        (unmasked_embeddings, masked_embeddings, unmasked_positions) = self.patch_encoder(patches)\n",
        "        encoder_outputs = self.encoder(unmasked_embeddings)\n",
        "        encoder_outputs = encoder_outputs + unmasked_positions\n",
        "        decoder_inputs = tf.concat([encoder_outputs, masked_embeddings], axis=1)\n",
        "        decoder_outputs = self.decoder(decoder_inputs)\n",
        "        total_loss = self.loss(patches, decoder_outputs)    \n",
        "        return {\"loss\": total_loss}"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIkD1iQfMiZV"
      },
      "source": [
        "! pip install -q tensorflow-addons\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S5OCq-QLIoC"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "augmentation_model = get_augmentation_model()\n",
        "patch_layer = Patches(patch_size=PATCH_SIZE)\n",
        "patch_encoder = PatchEncoder(patch_size=PATCH_SIZE, projection_dim=PROJECTION_DIM, batch_size=BATCH_SIZE)\n",
        "encoder = Encoder(num_layers=TRANSFORMER_LAYERS, num_heads=NUM_HEADS)\n",
        "decoder = Decoder(num_layers=TRANSFORMER_LAYERS, num_heads=NUM_HEADS, patch_size=PATCH_SIZE)\n",
        "\n",
        "mae = MaskedAutoencoder(\n",
        "    augmentation_model=augmentation_model,\n",
        "    patch_layer=patch_layer,\n",
        "    patch_encoder=patch_encoder,\n",
        "    encoder=encoder,\n",
        "    decoder=decoder)\n",
        "\n",
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "mae.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=keras.losses.MeanSquaredError(),\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lkHB5r3kQuQ",
        "outputId": "13f6be4d-19cc-4f8d-eb54-9fdd5a769be6"
      },
      "source": [
        "history = mae.fit(\n",
        "    train_ds,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - 54s 454ms/step - loss: 0.8503 - val_loss: 0.7441\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 0.7465 - val_loss: 0.7513\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 0.7247 - val_loss: 0.7311\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 0.7192 - val_loss: 0.7513\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 0.7184 - val_loss: 0.6999\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 0.7150 - val_loss: 0.7168\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 44s 439ms/step - loss: 0.7122 - val_loss: 0.7370\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 0.7136 - val_loss: 0.7150\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7142"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rr_h7O6Q7S_"
      },
      "source": [
        "loss = mae.evaluate(test_ds)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}